import type {
    ContainerCreateOptions,
    ContainerCreateResult,
    ContainerProviderConnection,
    Device,
    ListImagesOptions,
    PullEvent,
    DeviceRequest,
    ImageInfo,
    MountConfig,
    ProviderContainerConnection,
} from '@podman-desktop/api';

import * as extensionApi from '@podman-desktop/api';
import type { PodmanConnection } from '../../managers/podmanConnection';
import * as PodmanConnectionAPI from '../../managers/podmanConnection';
import { containerEngine, provider, ProgressLocation } from '@podman-desktop/api';

export const SECOND: number = 1_000_000_000;

const path = require('path');
const fs = require('fs');
const async_fs = require('fs/promises');

const AvailableModels = {};
let ExtensionStoragePath = undefined;

const FAIL_IF_NOT_MAC = true;
const EXTENSION_BUILD_PATH = path.parse(__filename).dir + "/../build";
const RESTRICT_OPEN_TO_GGUF_FILES = false;
const SEARCH_AI_LAB_MODELS = true;

let RamalamaRemotingImage = undefined;
let ApirVersion = undefined;
let LocalBuildDir = undefined;
let StatusBar = undefined;
let NoAiLabModelWarningShown = false;

function setStatus(status) {
    console.log(`API Remoting status: ${status}`)
    if (StatusBar === undefined) {
        console.warn("Status bar not available ...");
        return;
    }
    if (status === undefined) {
        StatusBar.text = `Llama.cpp API Remoting`
    } else {
        StatusBar.text = `Llama.cpp API Remoting: ${status}`
    }
}

function registerFromDir(startPath, filter, register) {
    if (!fs.existsSync(startPath)) {
        console.log("no dir ", startPath);
        return;
    }

    var files = fs.readdirSync(startPath);
    for (var i = 0; i < files.length; i++) {
        var filename = path.join(startPath, files[i]);
        var stat = fs.lstatSync(filename);
        if (stat.isDirectory()) {
            registerFromDir(filename, filter, register); //recurse
        } else if (filename.endsWith(filter)) {
            register(filename);
        };
    };
};

// generated by chatgpt
async function copyRecursive(src, dest) {
    const entries = await async_fs.readdir(src, { withFileTypes: true });

    await async_fs.mkdir(dest, { recursive: true });

    for (let entry of entries) {
        const srcPath = path.join(src, entry.name);
        const destPath = path.join(dest, entry.name);

        if (entry.isDirectory()) {
            await copyRecursive(srcPath, destPath);
        } else {
            await async_fs.copyFile(srcPath, destPath);
        }
    }
}

const getRandomString = (): string => {
    // eslint-disable-next-line sonarjs/pseudo-random
    return (Math.random() + 1).toString(36).substring(7);
};

function refreshAvailableModels() {
    if (!SEARCH_AI_LAB_MODELS) {
        console.log("Searching AI lab models is disabled. Skipping refreshAvailableModels.")
        return;
    }

    if (ExtensionStoragePath === undefined) throw new Error('ExtensionStoragePath not defined :/');

    // delete the existing models
    Object.keys(AvailableModels).forEach(key => delete AvailableModels[key]);

    const registerModel = function(filename) {
        const dir_name = filename.split("/").at(-2)
        const name_parts = dir_name.split(".")
        // 0 is the source (eg, hf)
        const model_dir = name_parts.at(1)
        const model_name = name_parts.slice(2).join('.')
        const model_user_name = `${model_dir}/${model_name}`
        AvailableModels[model_user_name] = filename;
        console.log(`found ${model_user_name}`)
    }

    registerFromDir(ExtensionStoragePath + '/../redhat.ai-lab/models', '.gguf', registerModel);
}

function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
}

async function hasApirContainerRunning() {
    const containerInfo = (await containerEngine.listContainers()).find(
        containerInfo =>
        containerInfo.Labels?.['llama-cpp.apir'] === 'true' &&
            containerInfo.State === 'running',
    );

    return containerInfo;
}

async function stopApirInferenceServer() {
    const containerInfo = await hasApirContainerRunning();
    if (containerInfo === undefined) {
        const msg = `üî¥ Could not find an API Remoting container running ...`
        setStatus(msg);
        await extensionApi.window.showErrorMessage(msg);
        return;
    }
    setStatus("‚öôÔ∏è Stopping the inference server ...")
    await containerEngine.stopContainer(containerInfo.engineId, containerInfo.Id);
    await checkPodmanMachineStatus(false);
}

async function showRamalamaChat() {
    const containerInfo = await hasApirContainerRunning();
    if (containerInfo === undefined) {
        const msg = `üî¥ Could not find an API Remoting container running ...`
        setStatus(msg);
        await extensionApi.window.showErrorMessage(msg);
        return;
    }
    const api_url = containerInfo?.Labels?.api;

    if (!api_url) {
        const msg = 'üî¥ Missing API URL label on the running APIR container.';
        setStatus(msg);
        await extensionApi.window.showErrorMessage(msg);
        return;
    }

    await extensionApi.window.showInputBox({
        title: "ramalama chat",
        prompt: "RamaLama command to chat with the API Remoting model",
        multiline: true,
        value: `ramalama chat --url "${api_url}"`,
    });
}

async function showRamalamaRun() {
    if (!RamalamaRemotingImage) {
        await extensionApi.window.showErrorMessage('APIR image is not loaded yet.');
        return;
    }
    await extensionApi.window.showInputBox({
        title: "ramalama run",
        prompt: "RamaLama command to launch a model",
        multiline: true,
        value: `ramalama run --image "${RamalamaRemotingImage}" llama3.2`,
    });
}

async function showRamalamaBenchmark() {
    if (!RamalamaRemotingImage) {
        await extensionApi.window.showErrorMessage('APIR image is not loaded yet.');
        return;
    }

    await extensionApi.window.showInputBox({
        title: "ramalama bench",
        prompt: "RamaLama commands to run benchmarks",
        multiline: true,
        value: `
# Venus-Vulkan benchmarking
ramalama bench llama3.2

# Native Metal benchmarking (needs \`llama-bench\` installed)
ramalama --nocontainer bench llama3.2

# API Remoting benchmark
ramalama bench  --image "${RamalamaRemotingImage}" llama3.2
# (scroll up to see more)`
    });
}

async function launchApirInferenceServer() {
    const containerInfo = await hasApirContainerRunning();
    if (containerInfo !== undefined) {
        const id = containerInfo.Id;
        console.error(`API Remoting container ${id} already running ...`);
        await extensionApi.window.showErrorMessage(`üü† API Remoting container ${id} is already running. This version cannot have two API Remoting containers running simultaneously.`);
        return;
    }

    if (RamalamaRemotingImage === undefined) throw new Error("Ramalama Remoting image name not loaded. This is unexpected.");

    setStatus("‚öôÔ∏è Configuring the inference server ...")
    let model_name;
    if (Object.keys(AvailableModels).length === 0) {
        if (!NoAiLabModelWarningShown) {
            await extensionApi.window.showInformationMessage(`üü† Could not find any model downloaded from AI Lab. Please select a GGUF file to load.`);
            NoAiLabModelWarningShown = true;
        }
        let uris = await extensionApi.window.showOpenDialog({
            title: "Select a GGUF model file",
            openLabel: "Select",
            canSelectFiles: true,
            canSelectFolders: false,
            canSelectMany: false,
            filters: { 'GGUF Models': ['gguf'] },
        })

        if (!uris || uris.length === 0) {
            console.log("No model selected, aborting the APIR container launch silently.")
            return;
        }
        model_name = uris[0].fsPath;

        if (RESTRICT_OPEN_TO_GGUF_FILES) {
            if (path.extname(model_name).toLowerCase() !== '.gguf') {
                const msg = `Selected file isn't a .gguf: ${model_name}`
                console.warn(msg);
                await extensionApi.window.showErrorMessage(msg);
                return;
            }
        }

        if (!fs.existsSync(model_name)){
            const msg = `Selected GGUF model file does not exist: ${model_name}`
            console.warn(msg);
            await extensionApi.window.showErrorMessage(msg);
            return;
        }


    } else {
        refreshAvailableModels();

        // display a choice to the user for selecting some values
        model_name = await extensionApi.window.showQuickPick(Object.keys(AvailableModels), {
            canPickMany: false, // user can select more than one choice
            title: "Choose the model to deploy",
        });
        if (model_name === undefined) {
            console.warn('No model chosen, nothing to launch.')
            return;
        }
    }

    // prepare the port

    const host_port_str = await extensionApi.window.showInputBox({
        title: "Service port",
        prompt: "Inference service port on the host",
        value: "1234",
        validateInput: (value) => (parseInt(value, 10) > 1024 ? "" : "Enter a valid port > 1024"),
    });
    const host_port = host_port_str ? parseInt(host_port_str, 10) : Number.NaN;

    if (Number.isNaN(host_port)) {
        console.warn('No host port chosen, nothing to launch.')
        return;
    }

    setStatus("‚öôÔ∏è Pulling the image ...")
    // pull the image
    const imageInfo: ImageInfo = await pullImage(
        RamalamaRemotingImage,
        {},
    );

    setStatus("‚öôÔ∏è Creating the container ...")
    // get model mount settings
    const model_src: string = AvailableModels[model_name] ?? model_name;

    if (model_src === undefined)
        throw new Error(`Couldn't get the file associated with model ${model_src}. This is unexpected.`);

    const model_filename = path.basename(model_src);
    const model_dirname = path.basename(path.dirname(model_src));
    const model_dest = `/models/${model_filename}`;
    const ai_lab_port = 10434;

    // prepare the labels
    const labels: Record<string, string> = {
        ['ai-lab-inference-server']: JSON.stringify([model_dirname]),
        ['api']: `http://127.0.0.1:${host_port}/v1`,
        ['docs']: `http://127.0.0.1:${ai_lab_port}/api-docs/${host_port}`,
        ['gpu']: `llama.cpp API Remoting`,
        ["trackingId"]: getRandomString(),
        ["llama-cpp.apir"]: "true",
    };

    // prepare the mounts
    // mount the file directory to avoid adding other files to the containers
    const mounts: MountConfig = [
        {
            Target: model_dest,
            Source: model_src,
            Type: 'bind',
            ReadOnly: true,
        },
    ];

    // prepare the entrypoint
    let entrypoint: string | undefined = undefined;
    let cmd: string[] = [];

    entrypoint = "/usr/bin/llama-server.sh";

    // prepare the env
    const envs: string[] = [`MODEL_PATH=${model_dest}`, 'HOST=0.0.0.0', 'PORT=8000', 'GPU_LAYERS=999'];

    // prepare the devices
    const devices: Device[] = [];
    devices.push({
        PathOnHost: '/dev/dri',
        PathInContainer: '/dev/dri',
        CgroupPermissions: '',
    });

    const deviceRequests: DeviceRequest[] = [];
    deviceRequests.push({
        Capabilities: [['gpu']],
        Count: -1, // -1: all
    });

    // Get the container creation options
    const containerCreateOptions: ContainerCreateOptions = {
        Image: imageInfo.Id,
        Detach: true,
        Entrypoint: entrypoint,
        Cmd: cmd,
        ExposedPorts: { [`${host_port}/tcp`]: {} },
        HostConfig: {
            AutoRemove: false,
            Devices: devices,
            Mounts: mounts,
            DeviceRequests: deviceRequests,
            SecurityOpt: ["label=disable"],
            PortBindings: {
                '8000/tcp': [
                    {
                        HostPort: `${host_port}`,
                    },
                ],
            },
        },

        HealthCheck: {
            // must be the port INSIDE the container not the exposed one
            Test: ['CMD-SHELL', `curl -sSf localhost:8000 > /dev/null`],
            Interval: SECOND * 5,
            Retries: 4 * 5,
        },
        Labels: labels,
        Env: envs,
    };
    console.log(containerCreateOptions, mounts)
    // Create the container
    const { engineId, id } = await createContainer(imageInfo.engineId, containerCreateOptions, labels);
    setStatus(`üéâ Inference server is ready on port ${host_port}`)
    await extensionApi.window.showInformationMessage(`üéâ ${model_name} is running with API Remoting acceleration!`);

}
export type BetterContainerCreateResult = ContainerCreateResult & { engineId: string };

async function createContainer(
    engineId: string,
    containerCreateOptions: ContainerCreateOptions,
    labels: { [id: string]: string },
): Promise<BetterContainerCreateResult> {

    console.log("Creating container ...");
    try {
        const result = await containerEngine.createContainer(engineId, containerCreateOptions);
        console.log("Container created!");

        // return the ContainerCreateResult
        return {
            id: result.id,
            engineId: engineId,
        };
    } catch (err: unknown) {
        const msg = `Container creation failed :/ ${String(err)}`
        console.error(msg);
        setStatus("üî¥ Container creation failed")
        await extensionApi.window.showErrorMessage(msg);
        throw err;
    }
}

function getConnection(allowUndefined = false): ContainerProviderConnection | undefined {
    const providers: ProviderContainerConnection[] = provider.getContainerConnections();
    const podmanProvider = providers.find(({ connection }) => connection.type === 'podman' && connection.status() === "started");
    if (!podmanProvider) {
        if (allowUndefined) {
            return undefined;
        } else {
            throw new Error('cannot find podman provider');
        }
    }
    let connection: ContainerProviderConnection = podmanProvider.connection;

    return connection;
}

async function pullImage(
    image: string,
    labels: { [id: string]: string },
): Promise<ImageInfo> {
    // Creating a task to follow pulling progress
    console.log(`Pulling the image ${image} ...`)
    const connection = getConnection();

    // get the default image info for this provider
    return getImageInfo(connection, image, (_event: PullEvent) => {})
        .catch((err: unknown) => {
            console.error(`Something went wrong while pulling ${image}: ${String(err)}`);
            throw err;
        })
        .then(imageInfo => {
            console.log("Image pulled successfully");
            return imageInfo;
        });
}

async function getImageInfo(
    connection: ContainerProviderConnection,
    image: string,
    callback: (event: PullEvent) => void,
): Promise<ImageInfo> {
    let imageInfo = undefined;

    try {
        // Pull image
        await containerEngine.pullImage(connection, image, callback);

        // Get image inspect
        imageInfo = (
            await containerEngine.listImages({
                provider: connection,
            } as ListImagesOptions)
        ).find(imageInfo => imageInfo.RepoTags?.some(tag => tag === image));

    } catch (err: unknown) {
        console.warn('Something went wrong while trying to get image inspect', err);
        await extensionApi.window.showErrorMessage(`Something went wrong while trying to get image inspect: ${err}`);

        throw err;
    }

    if (imageInfo === undefined) throw new Error(`image ${image} not found.`);

    return imageInfo;
}

async function initializeBuildDir(buildPath) {
    console.log(`Initializing the build directory from ${buildPath} ...`)

    ApirVersion = (await async_fs.readFile(buildPath + '/src_info/version.txt', 'utf8')).replace(/\n$/, "");

    if (RamalamaRemotingImage === undefined)
        RamalamaRemotingImage = (await async_fs.readFile(buildPath + '/src_info/ramalama.image-info.txt', 'utf8')).replace(/\n$/, "");
}

async function initializeStorageDir(storagePath, buildPath) {
    console.log(`Initializing the storage directory ...`)

    if (!fs.existsSync(storagePath)){
        fs.mkdirSync(storagePath);
    }

    if (ApirVersion === undefined) throw new Error("APIR version not loaded. This is unexpected.");

    LocalBuildDir = `${storagePath}/${ApirVersion}`;
    if (!fs.existsSync(LocalBuildDir)){
        await copyRecursive(buildPath, LocalBuildDir)
        console.log('Copy complete');
    }
}

export async function activate(extensionContext: extensionApi.ExtensionContext): Promise<void> {
    // initialize the global variables ...
    ExtensionStoragePath = extensionContext.storagePath;
    console.log("Activating the API Remoting extension ...")

    // register the command referenced in package.json file
    const menuCommand = extensionApi.commands.registerCommand('llama.cpp.apir.menu', async () => {
        if (FAIL_IF_NOT_MAC && !extensionApi.env.isMac) {
            await extensionApi.window.showErrorMessage(`llama.cpp API Remoting only supported on MacOS.`);
            return;
        }

        let status = "(status is undefined)";
        try {
            status = await checkPodmanMachineStatus(false)
        } catch (err: unknown) {
            await extensionApi.window.showErrorMessage(err);
            return;
        }

        const main_menu_choices: Record<string, () => Promise<void> | void> = {};
        // status values:

        //  0 ==> running with API Remoting support
        // 10 ==> running vfkit VM instead of krunkit
        // 11 ==> krunkit not running
        // 12 ==> krunkit running without API Remoting
        // 2x ==> script cannot run correctly

        //  1 ==> running with a container launched
        //127 ==> APIR files not available

        let status_str;
        if (status === 127) { // files have been uninstalled
            status_str = "API Remoting binaries are not installed"
            main_menu_choices["Reinstall the API Remoting binaries"] = installApirBinaries;

        } else if (status === 0 || status === 1) { // running with API Remoting support
            if (status === 0) {
                status_str = "VM is running with API Remoting üéâ"
                main_menu_choices["Launch an API Remoting accelerated Inference Server"] = launchApirInferenceServer;
                main_menu_choices["Show RamaLama model launch command"] = showRamalamaRun;
                main_menu_choices["Show RamaLama benchmark commands"] = showRamalamaBenchmark;
            } else {
                status_str = "an API Remoting inference server is already running"
                main_menu_choices["Show RamaLama chat command"] = showRamalamaChat;
                main_menu_choices["Stop the API Remoting Inference Server"] = stopApirInferenceServer;
            }
            main_menu_choices["---"] = function() {};
            main_menu_choices["Restart PodMan Machine without API Remoting"] = restart_podman_machine_without_apir;

        } else if (status === 10 || status === 11 || status === 12) {
            if (status === 10) {
                status_str = "VM is running with vfkit";
            } else if (status === 11) {
                status_str = "VM is not running";
            } else if (status === 12) {
                status_str = "VM is running without API Remoting";
            }
            main_menu_choices["Restart PodMan Machine with API Remoting support"] = restart_podman_machine_with_apir;
            main_menu_choices["Uninstall the API Remoting binaries"] = uninstallApirBinaries;
        }

        main_menu_choices["---"] = function() {};
        main_menu_choices["Check PodMan Machine API Remoting status"] = () => checkPodmanMachineStatus(true);

        // display a choice to the user for selecting some values
        const result = await extensionApi.window.showQuickPick(Object.keys(main_menu_choices), {
            title: `What do
you want to do? (${status_str})`,
            canPickMany: false, // user can select more than one choice
        });

        if (result === undefined) {
            console.log("No user choice, aborting.");
            return;
        }

        try {
            await main_menu_choices[result]();
        } catch (err: unknown) {
            const msg = `Task failed: ${String(err)}`;
            console.error(msg);
            await extensionApi.window.showErrorMessage(msg);

            throw err;
        }
    });

    try {
        // create an item in the status bar to run our command
        // it will stick on the left of the status bar
        StatusBar = extensionApi.window.createStatusBarItem(extensionApi.StatusBarAlignLeft, 100);

        setStatus("‚öôÔ∏è Initializing ...");
        StatusBar.command = 'llama.cpp.apir.menu';
        StatusBar.show();

        // register disposable resources to it's removed when you deactivte the extension
        extensionContext.subscriptions.push(menuCommand);
        extensionContext.subscriptions.push(StatusBar);
    } catch (error) {
        const msg = `Couldn't subscribe the extension to Podman Desktop: ${error}`

        await extensionApi.window.showErrorMessage(msg);
        throw new Error(msg);
    }

    try {
        setStatus("Installing ...")
        await installApirBinaries();
    } catch (error) {
        return; // message already printed on screen
    }

    setStatus(`‚öôÔ∏è Loading the models ...`);
    try {
        refreshAvailableModels();
    } catch (error) {
        const msg = `Couldn't initialize the extension: ${error}`

        await extensionApi.window.showErrorMessage(msg);
        setStatus(`üî¥ ${msg}`);
        return
    }

    setStatus();
}

export async function deactivate(): Promise<void> {

}

async function installApirBinaries() {
    try {
        await initializeBuildDir(EXTENSION_BUILD_PATH);
        console.log(`Installing APIR version ${ApirVersion} ...`);
        StatusBar.tooltip = `version ${ApirVersion}`;
        console.log(`Using image ${RamalamaRemotingImage}`);

        setStatus(`‚öôÔ∏è Extracting the binaries ...`);
        await initializeStorageDir(ExtensionStoragePath, EXTENSION_BUILD_PATH);

        setStatus(`‚öôÔ∏è Preparing krunkit ...`);
        await prepare_krunkit();
        setStatus(`‚úÖ binaries installed`);
    } catch (error) {
        const msg = `Couldn't initialize the extension: ${error}`
        setStatus(`üî¥ ${msg}`);
        await extensionApi.window.showErrorMessage(msg);
        throw error;
    }
}

async function uninstallApirBinaries() {
    if (ExtensionStoragePath === undefined) throw new Error('ExtensionStoragePath not defined :/');
    setStatus(`‚öôÔ∏è Uninstalling the binaries ...`);
    const toDelete = [];

    registerFromDir(ExtensionStoragePath, 'check_podman_machine_status.sh', function(filename) {toDelete.push(path.dirname(filename))});

    for (const dirName of toDelete) {
        console.warn("‚ö†Ô∏è deleting APIR directory: ", dirName);

        fs.rmSync(dirName, { recursive: true, force: true });
    }
    console.warn("‚ö†Ô∏è deleting done");

    setStatus(`‚úÖ binaries uninstalled üëã`);
}

async function getConnectionName(allowUndefined = false): Promise<string | undefined> {
    try {
        const connection = getConnection(allowUndefined);
        const connectionName = connection?.["name"];

        if (!allowUndefined && connectionName === undefined) {
            throw new Error('cannot find podman connection name');
        }
        if (connectionName) {
            console.log("Connecting to", connectionName);
        }
        return connectionName;
    } catch (error) {
        const msg = `Failed to get the default connection to Podman: ${error}`
        await extensionApi.window.showErrorMessage(msg);
        console.error(msg);
        setStatus(`üî¥ ${msg}`);
        throw new Error(msg);
    }
}

async function restart_podman_machine_with_apir(): Promise<void> {
    if (LocalBuildDir === undefined) throw new Error("LocalBuildDir not loaded. This is unexpected.");

    const connectionName = await getConnectionName(true);

    try {
        setStatus("‚öôÔ∏è Restarting PodMan Machine with API Remoting support ...")
        const args = ["bash", `${LocalBuildDir}/podman_start_machine.api_remoting.sh`];
        if (connectionName !== undefined) {
            args.push(connectionName);
            console.log(`Using connection ${connectionName}`);
        } else {
            console.log(`Using the default connection`);
        }

        const { stdout } = await extensionApi.process.exec("/usr/bin/env", args, {cwd: LocalBuildDir});

        const msg = "üü¢ PodMan Machine successfully restarted with API Remoting support"
        await extensionApi.window.showInformationMessage(msg);
        console.log(msg);
        setStatus("üü¢ API Remoting support enabled");
    } catch (error) {
        const msg = `Failed to restart PodMan Machine with the API Remoting support: ${error}`
        await extensionApi.window.showErrorMessage(msg);
        console.error(msg);
        setStatus(`üî¥ ${msg}`);
        throw new Error(msg);
    }
}

async function restart_podman_machine_without_apir(): Promise<void> {
    const connectionName = await getConnectionName();

    try {
        setStatus("‚öôÔ∏è Stopping the PodMan Machine ...")
        const { stdout } = await extensionApi.process.exec("podman", ['machine', 'stop', connectionName]);
    } catch (error) {
        const msg = `Failed to stop the PodMan Machine: ${error}`;
        setStatus(`üî¥ ${msg}`);
        await extensionApi.window.showErrorMessage(msg);
        console.error(msg);
        throw new Error(msg);
    }

    try {
        setStatus("‚öôÔ∏è Restarting the default PodMan Machine ...")
        const { stdout } = await extensionApi.process.exec("podman", ['machine', 'start', connectionName]);
    } catch (error) {
        const msg = `Failed to restart the PodMan Machine: ${error}`;
        setStatus(`üî¥ ${msg}`);
        await extensionApi.window.showErrorMessage(msg);
        console.error(msg);
        throw new Error(msg);
    }

    const msg = "PodMan Machine successfully restarted without API Remoting support";
    await extensionApi.window.showInformationMessage(msg);
    console.log(msg);
    setStatus("üü† Running without API Remoting support")
}

async function prepare_krunkit(): Promise<void> {
    if (LocalBuildDir === undefined) throw new Error("LocalBuildDir not loaded. This is unexpected.");

    if (fs.existsSync(`${LocalBuildDir}/bin/krunkit`)) {
        console.log("Binaries already prepared.")
        return;
    }

    setStatus(`‚öôÔ∏è Preparing the krunkit binaries for API Remoting ...`);
    if (!fs.existsSync(`${LocalBuildDir}/update_krunkit.sh`)) {
        const msg = `Cannot prepare the krunkit binaries: ${LocalBuildDir}/update_krunkit.sh does not exist`
        console.error(msg);
        throw new Error(msg);
    }

    try {
        const { stdout } = await extensionApi.process.exec("/usr/bin/env", ["bash", `${LocalBuildDir}/update_krunkit.sh`], {cwd: LocalBuildDir});
    } catch (error) {
        console.error(error);
        throw new Error(`Couldn't update the krunkit binaries: ${error}: ${error.stdout}`);
    }
    setStatus(`‚úÖ binaries prepared!`);
}

async function checkPodmanMachineStatus(with_gui: boolean): Promise<number> {
    if (!fs.existsSync(`${LocalBuildDir}/check_podman_machine_status.sh`)) {
        console.log(`checkPodmanMachineStatus: script not found in ${LocalBuildDir}`)
        setStatus("‚õî not installed");
        if (with_gui) {
            await extensionApi.window.showInformationMessage("‚õî API Remoting binaries are not installed");
        }
        return 127;
    }

    try {
        const { stdout } = await extensionApi.process.exec("/usr/bin/env", ["bash", `${LocalBuildDir}/check_podman_machine_status.sh`], {cwd: LocalBuildDir});
        // exit with success, krunkit is running API remoting
        const status = stdout.replace(/\n$/, "")
        const msg = `Podman Machine API Remoting status:\n${status}`
        if (with_gui) {
            await extensionApi.window.showInformationMessage(msg);
        }
        console.log(msg);
        const containerInfo = await hasApirContainerRunning();
        if (containerInfo !== undefined) {
            setStatus(`üü¢ Inference Server running`);
            return 1;
        } else {
            setStatus("üü¢");
            return 0;
        }

    } catch (error) {
        let msg;
        const status = error.stdout.replace(/\n$/, "")
        const exitCode = error.exitCode;

        if (exitCode > 10 && exitCode < 20) {
            // exit with code 1x ==> successful completion, but not API Remoting support
            msg =`üü† Podman Machine status: ${status}`;
            if (with_gui) {
                await extensionApi.window.showInformationMessage(msg);
            }
            console.warn(msg)
            if (exitCode === 10 || exitCode === 12) {
                setStatus("üü† PodMan Machine running without API Remoting support");
            } else if (exitCode === 11) {
                setStatus("üü† PodMan Machine not running");
            } else {
                setStatus(`üî¥ Invalid check status ${exitCode}`)
                console.warn(`Invalid check status ${exitCode}: ${error.stdout}`)
            }

            return exitCode;
        }

        // other exit code crash of unsuccessful completion
        msg =`Failed to check PodMan Machine status: ${status} (code #${exitCode})`;
        await extensionApi.window.showErrorMessage(msg);
        console.error(msg);
        setStatus(`üî¥ ${msg}`)
        throw new Error(msg);
    }
}
